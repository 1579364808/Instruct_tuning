{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "import torch\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding,EarlyStoppingCallback\nimport evaluate\nimport pandas as pd\nimport zipfile\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-27T15:03:02.444655Z",
     "iopub.execute_input": "2025-02-27T15:03:02.444950Z",
     "iopub.status.idle": "2025-02-27T15:03:09.625326Z",
     "shell.execute_reply.started": "2025-02-27T15:03:02.444919Z",
     "shell.execute_reply": "2025-02-27T15:03:09.624617Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# 设置随机种子\ntorch.manual_seed(42)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-27T15:03:09.626499Z",
     "iopub.execute_input": "2025-02-27T15:03:09.627212Z",
     "iopub.status.idle": "2025-02-27T15:03:09.634501Z",
     "shell.execute_reply.started": "2025-02-27T15:03:09.627177Z",
     "shell.execute_reply": "2025-02-27T15:03:09.633835Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "GLUE（General Language Understanding Evaluation）是一个常用的自然语言处理（NLP）基准数据集集合。\"sst2\": 这是 GLUE 数据集中的一个子集，全称是 Stanford Sentiment Treebank v2，用于情感分析任务。它包含句子及其对应的情感标签（正面或负面）。",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# 加载数据集\ntrain_dataset = load_dataset(\"glue\", \"sst2\", split=\"train[:64]\")\nval_dataset = load_dataset(\"glue\", \"sst2\", split=\"validation\")\ntest_dataset = load_dataset(\"glue\", \"sst2\", split=\"test\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T11:29:34.080918Z",
     "start_time": "2025-02-27T11:28:57.712699Z"
    },
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-27T15:03:09.636051Z",
     "iopub.execute_input": "2025-02-27T15:03:09.636276Z",
     "iopub.status.idle": "2025-02-27T15:03:18.222118Z",
     "shell.execute_reply.started": "2025-02-27T15:03:09.636255Z",
     "shell.execute_reply": "2025-02-27T15:03:18.221469Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "[GLUE数据集的详细介绍](https://mp.weixin.qq.com/s?__biz=MzUzMDk1MjUzMQ==&mid=2247483653&idx=1&sn=cae5edc4fb48bc668325d4197e92b3c8&chksm=fbc2783f20713519586dd6b0aab98e52fe89ff344417d00a352164c316fef4f3adf4ea5e9687#rd)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# 加载 DeBERTa 的分词器和模型\nmodel_name = \"microsoft/deberta-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T11:30:24.981724Z",
     "start_time": "2025-02-27T11:29:35.356874Z"
    },
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-27T15:03:18.223504Z",
     "iopub.execute_input": "2025-02-27T15:03:18.223833Z",
     "iopub.status.idle": "2025-02-27T15:03:19.327710Z",
     "shell.execute_reply.started": "2025-02-27T15:03:18.223801Z",
     "shell.execute_reply": "2025-02-27T15:03:19.326692Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 修改 tokenize_function，不再使用固定的 max_length，而是使用 padding=True\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"sentence\"],\n",
    "        padding=True,       # 使用动态填充\n",
    "        truncation=True,    # 保证文本不会超过最大长度\n",
    "        max_length=512\n",
    "    )\n",
    "# 对训练集和验证集进行分词处理\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val = val_dataset.map(tokenize_function, batched=True)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T11:30:25.990941Z",
     "start_time": "2025-02-27T11:30:25.049178Z"
    },
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-27T15:03:19.329012Z",
     "iopub.execute_input": "2025-02-27T15:03:19.329358Z",
     "iopub.status.idle": "2025-02-27T15:03:19.511967Z",
     "shell.execute_reply.started": "2025-02-27T15:03:19.329324Z",
     "shell.execute_reply": "2025-02-27T15:03:19.511095Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# 使用 DataCollatorWithPadding 来确保每个批次按最大序列长度动态填充\ndata_collator = DataCollatorWithPadding(tokenizer)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T11:30:26.078322Z",
     "start_time": "2025-02-27T11:30:26.030716Z"
    },
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-27T15:03:19.513060Z",
     "iopub.execute_input": "2025-02-27T15:03:19.513379Z",
     "iopub.status.idle": "2025-02-27T15:03:19.516715Z",
     "shell.execute_reply.started": "2025-02-27T15:03:19.513346Z",
     "shell.execute_reply": "2025-02-27T15:03:19.515876Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# 加载准确率指标\nmetric = evaluate.load(\"accuracy\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-27T15:03:19.517607Z",
     "iopub.execute_input": "2025-02-27T15:03:19.517947Z",
     "iopub.status.idle": "2025-02-27T15:03:20.096941Z",
     "shell.execute_reply.started": "2025-02-27T15:03:19.517887Z",
     "shell.execute_reply": "2025-02-27T15:03:20.096249Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = logits.argmax(axis=-1)  # 将 logits 转换为预测标签\n    return metric.compute(predictions=predictions, references=labels)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-27T15:03:20.098830Z",
     "iopub.execute_input": "2025-02-27T15:03:20.099059Z",
     "iopub.status.idle": "2025-02-27T15:03:20.102961Z",
     "shell.execute_reply.started": "2025-02-27T15:03:20.099039Z",
     "shell.execute_reply": "2025-02-27T15:03:20.102083Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "datasets 库默认返回的数据格式是 Python 的字典或列表。如果你使用 PyTorch 进行训练，需要将数据转换为 PyTorch 张量（torch.Tensor），因为 PyTorch 模型和优化器只能处理张量。如果你使用 transformers.Trainer：不需要手动执行 set_format。Trainer 会自动处理数据格式转换",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# 设置训练参数\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",           # 输出目录\n    evaluation_strategy=\"steps\",      # 每 10 步后进行评估\n    eval_steps=10,                    # 每 10 步评估一次\n    learning_rate=1e-5,               # 学习率\n    per_device_train_batch_size=16,  # 训练批次大小\n    per_device_eval_batch_size=256,   # 评估批次大小\n    num_train_epochs=3,               # 训练 epoch 数\n    weight_decay=0.01,                # 权重衰减\n    save_strategy=\"steps\",            # 每个 epoch 后保存模型\n    save_total_limit=5,               # 最多保存一个检查点\n    logging_dir=\"./logs\",             # 日志目录\n    logging_steps=10,                 # 每 10 步记录一次日志\n    gradient_accumulation_steps=1,    # 梯度累积步数\n    dataloader_num_workers=4,        # 增加数据加载进程\n    report_to=\"none\",                # 不报告到任何系统（如 Wandb）\n    metric_for_best_model=\"eval_loss\", \n    load_best_model_at_end=True,      # 在训练结束时加载最好的模型\n)\n\n",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T11:30:30.806378Z",
     "start_time": "2025-02-27T11:30:28.874508Z"
    },
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-27T15:03:20.104368Z",
     "iopub.execute_input": "2025-02-27T15:03:20.104627Z",
     "iopub.status.idle": "2025-02-27T15:03:20.202677Z",
     "shell.execute_reply.started": "2025-02-27T15:03:20.104607Z",
     "shell.execute_reply": "2025-02-27T15:03:20.201722Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# 设置早停回调\nearly_stopping_callback = EarlyStoppingCallback(early_stopping_patience=10)  # 5次没有改进时停止\n# 定义 Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_val,\n    compute_metrics=compute_metrics,  # 使用 compute_metrics 函数\n    data_collator=data_collator,     # 使用数据整理器来动态填充\n    callbacks=[early_stopping_callback] # 加入早停回调\n)\n# 开始训练\ntrainer.train()",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-27T15:03:20.204077Z",
     "iopub.execute_input": "2025-02-27T15:03:20.204403Z",
     "iopub.status.idle": "2025-02-27T15:06:19.201681Z",
     "shell.execute_reply.started": "2025-02-27T15:03:20.204369Z",
     "shell.execute_reply": "2025-02-27T15:06:19.200881Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# 对测试集进行分词处理\ntokenized_test = test_dataset.map(tokenize_function, batched=True)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-27T15:06:19.202664Z",
     "iopub.execute_input": "2025-02-27T15:06:19.202938Z",
     "iopub.status.idle": "2025-02-27T15:06:19.398371Z",
     "shell.execute_reply.started": "2025-02-27T15:06:19.202915Z",
     "shell.execute_reply": "2025-02-27T15:06:19.397656Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# 在测试集上进行预测\npredictions = trainer.predict(tokenized_test)\n\n# 获取预测结果\npredicted_labels = predictions.predictions.argmax(axis=-1)  # 将 logits 转换为预测标签",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-27T15:06:19.399083Z",
     "iopub.execute_input": "2025-02-27T15:06:19.399300Z",
     "iopub.status.idle": "2025-02-27T15:06:23.353582Z",
     "shell.execute_reply.started": "2025-02-27T15:06:19.399272Z",
     "shell.execute_reply": "2025-02-27T15:06:23.352822Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "import pandas as pd\nimport zipfile\n\n# 生成提交文件\nsubmission = pd.DataFrame({\n    \"id\": test_dataset[\"idx\"],  # 测试集的索引列\n    \"label\": predicted_labels  # 预测标签\n})\n\n# 保存为 TSV 文件（制表符分隔）\nsubmission.to_csv(\"SST-2.tsv\", sep=\"\\t\", index=False)\n\n# 压缩为 ZIP 文件\nwith zipfile.ZipFile(\"submission.zip\", \"w\") as zipf:\n    zipf.write(\"SST-2.tsv\", arcname=\"SST-2.tsv\")\n\nprint(\"提交文件已生成并压缩为 submission.zip\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-27T15:06:23.354511Z",
     "iopub.execute_input": "2025-02-27T15:06:23.354877Z",
     "iopub.status.idle": "2025-02-27T15:06:23.368369Z",
     "shell.execute_reply.started": "2025-02-27T15:06:23.354848Z",
     "shell.execute_reply": "2025-02-27T15:06:23.367510Z"
    }
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
